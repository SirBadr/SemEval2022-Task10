{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9a03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./Data/starting_ki/train_all_tasks.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4faed7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(data_path)\n",
    "data = data[data[\"label_category\"]!=\"none\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e5203fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prejudiced discussion\n"
     ]
    }
   ],
   "source": [
    "label_category_map = {\n",
    "    \"1. threats, plans to harm and incitement\":\"Threat\",\n",
    "    \"2. derogation\":\"Derogation\",\n",
    "    \"3. animosity\":\"Animosity\",\n",
    "    \"4. prejudiced discussions\":\"Prejudiced discussion\",\n",
    "    \"Threat\":\"1. threats, plans to harm and incitement\",\n",
    "    \"Derogation\":\"2. derogation\",\n",
    "    \"Animosity\":\"3. animosity\",\n",
    "    \"Prejudiced discussion\":\"4. prejudiced discussions\"\n",
    "}\n",
    "print(label_category_map[\"4. prejudiced discussions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bc67f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# function returns two random text samples to use them as GPT-J prompt\n",
    "def get_three_random_samples(data_frame):\n",
    "    # get two random samples from `data file`\n",
    "    s1, s2, s3 = random.sample(range(0, len(data)), 3)\n",
    "    print(s1,s2,s3)\n",
    "    # get text labels\n",
    "    label1 = label_category_map[data_frame['label_category'].iloc[s1]]\n",
    "    label2 = label_category_map[data_frame['label_category'].iloc[s2]]\n",
    "    label3 = label_category_map[data_frame['label_category'].iloc[s3]]\n",
    "#     print(label_category_map[label1])\n",
    "    \n",
    "    # return text1, label1, text2, label2\n",
    "    return data_frame['text'].iloc[s1], label1, data_frame['text'].iloc[s2], label2, data_frame['text'].iloc[s3], label3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd01f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(text1, label1, text2, label2, text3, label3):\n",
    "    # define a function that takes as input three samples and generates the prompt\n",
    "    # that we should pass to the GPT-3 language model for completion.\n",
    "    description = \"Each item in the following list contains a sexist tweet and the respective category. Category is one of 'Threat', 'Derogation', 'Animosity', or 'Prejudiced discussion'\"\n",
    "    prompt = (f\"{description}\\n\"\n",
    "            f\"Tweet: {text1} (Sentiment: {label1})\\n\"\n",
    "            f\"Tweet: {text2} (Sentiment: {label2})\\n\"\n",
    "            f\"Tweet: {text3} (Sentiment: {label3})\\n\"\n",
    "            f\"Tweet:\")\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98b273e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1695 2109 2126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Each item in the following list contains a sexist tweet and the respective category. Category is one of 'Threat', 'Derogation', 'Animosity', or 'Prejudiced discussion'\\nTweet: It was rape because she regretted it afterwards, duh. There's no way she could have sex with a nerd. Sheesh. (Sentiment: Prejudiced discussion)\\nTweet: Lol guys, I seen the original, it's posted by a mum xD even the mum is a whore and won't tell her daughter off. (Sentiment: Derogation)\\nTweet: HAHAHA! Why would an alpha get married to an old hag when he has literally hundreds of hot 18-19 year olds (and older bitches too but eeewww amirite??) begging him to fuck them? Feeeemale logic. (Sentiment: Derogation)\\nTweet:\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c,d,e,f=get_three_random_samples(data)\n",
    "get_prompt(a,b,c,d,e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a32c06c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-large\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2-large\", pad_token_id=tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94e02776",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list=[]\n",
    "res_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e49bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2338 2013 2852\n",
      "Each item in the following list contains a sexist tweet and the respective category. Category is one of 'Threat', 'Derogation', 'Animosity', or 'Prejudiced discussion'\n",
      "Tweet: if women want men to be responsible for babies they make they shouldnt make them unless married (Sentiment: Animosity)\n",
      "Tweet: To think all women are trying to repress this feeling... that is female over-eagerness. (Sentiment: Derogation)\n",
      "Tweet: [URL] This cunt is Antifa. (Sentiment: Animosity)\n",
      "Tweet:\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d,e,f=get_three_random_samples(data)\n",
    "sentence = get_prompt(a,b,c,d,e,f)\n",
    "prompt_list.append(sentence)\n",
    "print(sentence)\n",
    "print(\"===================================\")\n",
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "output = model.generate(input_ids, max_length=250, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "ans=tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(ans)\n",
    "print(\"===================================\")\n",
    "                                                            \n",
    "res_list.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01323091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ff0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
