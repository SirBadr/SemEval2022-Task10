{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9a03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./Data/starting_ki/train_all_tasks.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4faed7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(data_path)\n",
    "data = data[data[\"label_category\"]!=\"none\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5203fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prejudiced discussion\n"
     ]
    }
   ],
   "source": [
    "label_category_map = {\n",
    "    \"1. threats, plans to harm and incitement\":\"Threat\",\n",
    "    \"2. derogation\":\"Derogation\",\n",
    "    \"3. animosity\":\"Animosity\",\n",
    "    \"4. prejudiced discussions\":\"Prejudiced discussion\",\n",
    "    \"Threat\":\"1. threats, plans to harm and incitement\",\n",
    "    \"Derogation\":\"2. derogation\",\n",
    "    \"Animosity\":\"3. animosity\",\n",
    "    \"Prejudiced discussion\":\"4. prejudiced discussions\"\n",
    "}\n",
    "print(label_category_map[\"4. prejudiced discussions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc67f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# function returns two random text samples to use them as GPT-J prompt\n",
    "def get_three_random_samples(data_frame):\n",
    "    # get two random samples from `data file`\n",
    "    s1, s2, s3 = random.sample(range(0, len(data)), 3)\n",
    "    print(s1,s2,s3)\n",
    "    # get text labels\n",
    "    label1 = label_category_map[data_frame['label_category'].iloc[s1]]\n",
    "    label2 = label_category_map[data_frame['label_category'].iloc[s2]]\n",
    "    label3 = label_category_map[data_frame['label_category'].iloc[s3]]\n",
    "#     print(label_category_map[label1])\n",
    "    \n",
    "    # return text1, label1, text2, label2\n",
    "    return data_frame['text'].iloc[s1], label1, data_frame['text'].iloc[s2], label2, data_frame['text'].iloc[s3], label3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd01f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(text1, label1, text2, label2, text3, label3):\n",
    "    # define a function that takes as input three samples and generates the prompt\n",
    "    # that we should pass to the GPT-3 language model for completion.\n",
    "    description = \"Each item in the following list contains a sexist tweet and the respective category. Category is one of 'Threat', 'Derogation', 'Animosity', or 'Prejudiced discussion'\"\n",
    "    prompt = (f\"{description}\\n\"\n",
    "            f\"Tweet: {text1} (Sentiment: {label1})\\n\"\n",
    "            f\"Tweet: {text2} (Sentiment: {label2})\\n\"\n",
    "            f\"Tweet: {text3} (Sentiment: {label3})\\n\"\n",
    "            f\"Tweet:\")\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98b273e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 503 1991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Each item in the following list contains a sexist tweet and the respective category. Category is one of 'Threat', 'Derogation', 'Animosity', or 'Prejudiced discussion'\\nTweet: I like 19 year old pussy. I know, call me crazy... (Sentiment: Derogation)\\nTweet: #SoLikeUs I guess I failed as a parent when I didn't dress my daughter up in a tiara and have her and all her friends get humped for her 8th birthday. I guess this explains why 2/3rds of all negresses aged 11-17 have STD's. (Sentiment: Derogation)\\nTweet: Chicks dig scars, maybe you should do a cool one your cheek. (Sentiment: Animosity)\\nTweet:\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b,c,d,e,f=get_three_random_samples(data)\n",
    "get_prompt(a,b,c,d,e,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a32c06c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ce1488f8d7445f9958e88d3b9c1ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e1c7aa799048ec89244b80dd796a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d2a39f057b44b39b0c8b66556f331b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507c75b2f15b4e14a40739a31d665794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd4a98eeed145ddaa1f8961021a05d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/131 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dca9184d2c4bbaa174bf40ff00f82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/948 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a3d75af1ba4219b5fa4c5e4a3506ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AutoTokenizer, AutoModelForCausalLM, pipeline, set_seed\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-xl\")\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"gpt2-xl\", pad_token_id=tokenizer.eos_token_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ML-Projects-Kiel/tweetyface\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ML-Projects-Kiel/tweetyface\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e02776",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_list=[]\n",
    "res_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a33e49bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1923 44 724\n",
      "Each item in the following list contains a sexist tweet and the respective category. Category is one of 'Threat', 'Derogation', 'Animosity', or 'Prejudiced discussion'\n",
      "Tweet: Alexandia Ocasio Cortez .. pretty gal should be in movies not in office (Sentiment: Derogation)\n",
      "Tweet: [USER] most moms are no sex at all, from all the complaints I hear. (Sentiment: Animosity)\n",
      "Tweet: And I thought 1960s hippies were ridiculous! They must be the offspring of slutty single mothers! They don't amass a lick of sense in their heads until they meet the real world which chews them up and spits them out! (Sentiment: Derogation)\n",
      "Tweet:\n",
      "===================================\n",
      "Each item in the following list contains a sexist tweet and the respective category. Category is one of 'Threat', 'Derogation', 'Animosity', or 'Prejudiced discussion'\n",
      "Tweet: Alexandia Ocasio Cortez.. pretty gal should be in movies not in office (Sentiment: Derogation)\n",
      "Tweet: [USER] most moms are no sex at all, from all the complaints I hear. (Sentiment: Animosity)\n",
      "Tweet: And I thought 1960s hippies were ridiculous! They must be the offspring of slutty single mothers! They don't amass a lick of sense in their heads until they meet the real world which chews them up and spits them out! (Sentiment: Derogation)\n",
      "Tweet: “You can’t change the world.” [User: elonmusk] The future of science is at stake. The world is not yet ready for the next epidemic, but you can change it if you have the courage to do something about it. I hope you do too. If you want to see what the future looks like, I recommend this book. A must-read for anyone who cares about science and technology.\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d,e,f=get_three_random_samples(data)\n",
    "sentence = get_prompt(a,b,c,d,e,f)\n",
    "prompt_list.append(sentence)\n",
    "print(sentence)\n",
    "print(\"===================================\")\n",
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "output = model.generate(input_ids, max_length=250, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "ans=tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(ans)\n",
    "print(\"===================================\")\n",
    "                                                            \n",
    "res_list.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01323091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ff0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
